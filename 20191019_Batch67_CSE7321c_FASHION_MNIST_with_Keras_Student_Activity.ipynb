{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install keras\n",
    "# pip install ann_visualizer\n",
    "# pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
    "\n",
    "Zalando seeks to replace the original MNIST dataset\n",
    "\n",
    "Each row is a separate image\n",
    "Column 1 is the class label.\n",
    "Remaining columns are pixel numbers (784 total).\n",
    "Each value is the darkness of the pixel (1 to 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train.iloc[:,1:])\n",
    "y_train = np.array(train.iloc[:,0])\n",
    "\n",
    "X_test = np.array(test.iloc[:,1:])\n",
    "y_test = np.array(test.iloc[:,0])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt    # For plotting \n",
    "%matplotlib inline                 \n",
    "\n",
    "s = np.random.choice(range(X_train.shape[0]), size=10, replace=False)  # Randomly select few samples\n",
    "\n",
    "print(s)\n",
    "plt.figure(figsize=(15,5))\n",
    "for i,j in enumerate(s):   \n",
    "    plt.subplot(2,5,i+1)                                # Subplot flag\n",
    "    plt.imshow(np.array(X_train[j]).reshape(28,28))     # Plot the image\n",
    "    plt.title('Product: '+str(y_train[j]))              # Target of the image\n",
    "    plt.xticks([])                                      # No X-Axis ticks\n",
    "    plt.yticks([])                                      # No Y-Axis ticks\n",
    "    plt.gray()                                          # For gray scale images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "0 T-shirt/top\n",
    "1 Trouser\n",
    "2 Pullover\n",
    "3 Dress\n",
    "4 Coat\n",
    "5 Sandal\n",
    "6 Shirt\n",
    "7 Sneaker\n",
    "8 Bag\n",
    "9 Ankle boot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the dimensions of the arrays\n",
    "print('x_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('x_test shape:  {}'.format(X_test.shape))\n",
    "print('y_test shape:  {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'to_categorical' converts the class lebels to one-hot vectors. One-hot vector is nothing but dummifying in R.\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential is a container which stores the layers in order. \n",
    "# Think of it as a train engine to which you can keep adding train cars. train car in our context will be a layer.\n",
    "# 'Dense' is a fully connected layer feedforward layer.\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a simple MLP\n",
    "\n",
    "model = Sequential() # This initializes a sequential model to which we can keep adding layers.\n",
    "model.add(Dense(10,input_shape=(784,), kernel_initializer='uniform', \n",
    "                activation='softmax')) # Add output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting learning and momentum\n",
    "# Adam is the optimizer which is the state of the art Gradient Descent variation. \n",
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # CrossEntropy is the loss function. \n",
    "              optimizer=adam,                  # Mention the optimizer\n",
    "              metrics=['accuracy'])            # Mention the metric to be printed while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epochs = 20\n",
    "# training the MLP model\n",
    "history = model.fit(X_train, y_train, epochs=nb_epochs, batch_size=64, \n",
    "                    validation_split=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt #plt is a visualization module in matplotlib.  \n",
    "%matplotlib inline \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building a simple MLP\n",
    "\n",
    "model = Sequential() # This initializes a sequential model to which we can keep adding layers.\n",
    "model.add(Dense(200, kernel_initializer='uniform', \n",
    "                input_dim = 784, activation='tanh')) # Add a dense layer \n",
    "model.add(Dense(10, kernel_initializer='uniform', \n",
    "                activation='softmax')) # Add output layer\n",
    "\n",
    "\n",
    "# Setting learning and momentum\n",
    "# Adam is the optimizer which is the state of the art Gradient Descent variation. \n",
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # CrossEntropy is the loss function. \n",
    "              optimizer=adam,                  # Mention the optimizer\n",
    "              metrics=['accuracy'])            # Mention the metric to be printed while training\n",
    "\n",
    "\n",
    "nb_epochs = 20\n",
    "# training the MLP model\n",
    "history = model.fit(X_train, y_train, epochs=nb_epochs, batch_size=64, \n",
    "                    validation_split=0.1) \n",
    "\n",
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt #plt is a visualization module in matplotlib.  \n",
    "%matplotlib inline \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "ann_viz(model,title=\"mlp neural network\",view=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN MLP CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation='relu',batch_size=64,random_state=1234,early_stopping=True,verbose=True,max_iter=25)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "sklearn_mlp_train_preds = mlp.predict(X_train)\n",
    "sklearn_mlp_test_preds = mlp.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_train,sklearn_mlp_train_preds))\n",
    "print(accuracy_score(y_test,sklearn_mlp_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mlp.loss_curve_)\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
